
%% bare_conf.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. The IEEE's font choices and paper sizes can   ***
% *** trigger bugs that do not appear when using other class files.       ***                          ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



\documentclass[conference]{IEEEtran}
% Some Computer Society conferences also require the compsoc mode option,
% but others use the standard conference format.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}





% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/pkg/ifpdf
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
%\usepackage{cite}
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of the IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off
% such as if a citation ever needs to be enclosed in parenthesis.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 5.0 (2009-03-20) and later if using hyperref.sty.
% The latest version can be obtained at:
% http://www.ctan.org/pkg/cite
% The documentation is contained in the cite.sty file itself.





\usepackage{url}
\usepackage[fleqn]{amsmath}
\usepackage{algorithm,algpseudocode}
\usepackage{mathtools}
\usepackage{gensymb}
\usepackage{xcolor,colortbl}
\usepackage{csquotes}
\usepackage{textcomp}
\usepackage{listings}

% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation
% can be obtained at: 
% http://www.ctan.org/pkg/graphicx
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found at:
% http://www.ctan.org/pkg/epslatex
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). The IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics.
%
% Note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/amsmath





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as the IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/pkg/algorithms
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/pkg/algorithmicx




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/array


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.




% *** SUBFIGURE PACKAGES ***
%\ifCLASSOPTIONcompsoc
%  \usepackage[caption=false,font=normalsize,labelfont=sf,textfont=sf]{subfig}
%\else
%  \usepackage[caption=false,font=footnotesize]{subfig}
%\fi
% subfig.sty, written by Steven Douglas Cochran, is the modern replacement
% for subfigure.sty, the latter of which is no longer maintained and is
% incompatible with some LaTeX packages including fixltx2e. However,
% subfig.sty requires and automatically loads Axel Sommerfeldt's caption.sty
% which will override IEEEtran.cls' handling of captions and this will result
% in non-IEEE style figure/table captions. To prevent this problem, be sure
% and invoke subfig.sty's "caption=false" package option (available since
% subfig.sty version 1.3, 2005/06/28) as this is will preserve IEEEtran.cls
% handling of captions.
% Note that the Computer Society format requires a larger sans serif font
% than the serif footnote size font used in traditional IEEE formatting
% and thus the need to invoke different subfig.sty package options depending
% on whether compsoc mode has been enabled.
%
% The latest version and documentation of subfig.sty can be obtained at:
% http://www.ctan.org/pkg/subfig




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure.
% Be aware that LaTeX2e kernels dated 2015 and later have fixltx2e.sty's
% corrections already built into the system in which case a warning will
% be issued if an attempt is made to load fixltx2e.sty as it is no longer
% needed.
% The latest version and documentation can be found at:
% http://www.ctan.org/pkg/fixltx2e


%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/pkg/stfloats
% Do not use the stfloats baselinefloat ability as the IEEE does not allow
% \baselineskip to stretch. Authors submitting work to the IEEE should note
% that the IEEE rarely uses double column equations and that authors should try
% to avoid such use. Do not be tempted to use the cuted.sty or midfloat.sty
% packages (also by Sigitas Tolusis) as the IEEE does not format its papers in
% such ways.
% Do not attempt to use stfloats with fixltx2e as they are incompatible.
% Instead, use Morten Hogholm'a dblfloatfix which combines the features
% of both fixltx2e and stfloats:
%
% \usepackage{dblfloatfix}
% The latest version can be found at:
% http://www.ctan.org/pkg/dblfloatfix




% *** PDF, URL AND HYPERLINK PACKAGES ***
%
%\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version and documentation can be obtained at:
% http://www.ctan.org/pkg/url
% Basically, \url{my_url_here}.




% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}


\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Energy Saving using Parallel Computing}


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{\IEEEauthorblockN{Gopal Menon}
\IEEEauthorblockA{Computer Science Department\\
Utah State University\\
Logan, Utah 84322\\
Email: gopal.menon@aggiemail.usu.edu}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract
% no keywords




% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle

\section{Introduction}

\subsection{Data Center Energy Consumption}
\label{sssec:num1}

Data centers are the backbone of the modern economy \cite{whitney}, from the server rooms
that power small to medium-sized organizations, to the enterprise data centers
that support american corporations, to the server farms that run cloud computing services hosted by amazon, Facebook, Google, and others. However, the explosion of digital content, big data, e-commerce, and Internet traffic is also making data centers one of the fastest-growing users of electricity in developed countries, and one of the key drivers in the construction of new power plants in the united states.\\

While most media and public attention focuses on the largest data centers that power so-called cloud computing operations - companies that provide web-based and other Internet services to consumers and businesses?these hyper-scale cloud computing data centers represent only a small fraction of data center energy consumption in the united states.\\

In 2013, U.S. data centers consumed an estimated 91 billion kilowatt-hours of electricity. This is the equivalent annual output of 34 large (500-megawatt) coal-fired power plants, enough electricity to power all the households in New York City twice over. Data center electricity consumption is projected to increase to roughly 140 billion kilowatt-hours annually by 2020, the equivalent annual output of 50 power plants, costing american businesses \$13 billion per year in electricity bills and causing the emission of nearly 150 million metric tons of carbon pollution annually.

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/DataCenterEfficiency.png}
\caption{Data Center Efficiency \cite{whitney}}
\label{DataCenterEfficiency}
\end{figure}
% no \IEEEPARstart

The data center energy usage is illustrated in figure \ref{DataCenterEfficiency}. The use of social media, email, tweets, song and movie downloads has resulted in growing demands on data centers. The internet traffic generated by this usage is shown in figure \ref{DataCenterUsage}.

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/DataCenterUsage.png}
\caption{Data Center Usage \cite{whitney}}
\label{DataCenterUsage}
\end{figure}

\definecolor{LightCyan}{rgb}{0.88,1,1}
\begin{table}[h!]
\centering
\caption{Estimated u.s. data center electricity consumption by market segment (2011) \cite{whitney}}
\label{tab:table1}
\begin{tabular}{ |l|r|r|r| } 
 \hline
\rowcolor{LightCyan}
 Segment & Servers (million) & Share & kWh/y \\ 
 \hline
 Small and Medium server rooms & 4.9 & 49\% & 37.5 \\ 
 \hline
 Enterprise/Corporate Data Centers & 3.7 & 27\% & 20.5 \\ 
 \hline
 Multi-Tenant Data Centers & 2.7 & 19\% & 14.1\\
 \hline
Hyper-scale Cloud Computing & 0.9 & 4\% & 3.3\\
\hline
High-Performance Computing & 0.1 & 1\% & 1.0\\
\hline
\rowcolor{LightCyan}
Total (rounded)   & 12.2 & 100\% & 76.4\\
\hline
\end{tabular}
\end{table}

The estimated energy consumption by market segment for the year 2011 is shown in table \ref{tab:table1}. As can be seen, the big cloud computing companies are very energy efficient and consume less that 5\% of the total energy consumed. 95\% of the energy is consumed by small, medium, corporate and multi-tenant operations.

\subsection{Problem Statement}

Until 2004, along with the increase in the number of transistors on a chip as per Moore\textquotesingle s law, there was also a rise in switching speed of the transistors \cite{mccool}. This translated into improved performance of microprocessors through a steady rise in their clock speeds.\\

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/ClockSpeed.png}
\caption{Growth of processor clock rates over time (log scale). This graph shows a dramatic halt by 2005 due to the power wall, although current processors are available over a diverse range of clock frequencies. \cite{mccool}}
\label{ClockSpeed}
\end{figure}

From 1973 to 2003, clock rates increased by three orders of magnitude, from about 1 MHz in 1973 to 1 GHz in 2003. However, as is clear from figure \ref{ClockSpeed} clock rates have now ceased to grow and are now generally in the 3 GHz range. In 2005, three factors converged to limit the growth in performance of single cores and shift new processor designs to the use of multiple cores \cite{mccool}. These are known as the \enquote{three walls}:

\begin{enumerate}
\item \textbf{Power wall:} Unacceptable growth in power usage with clock rate. 
\item \textbf{Instruction-level parallelism (ILP) wall:} Limits to available low-level parallelism. 
\item \textbf{Memory wall:} A growing discrepancy of processor speeds relative to memory speeds.
\end{enumerate}

The power wall results because power consumption (and heat generation) increases non-linearly as the clock rate increases. Increasing clock rates any further will exceed the power density that can be dealt with by air cooling, and also results in power-inefficient computation.\\

The second wall is the instruction-level parallelism (ILP) wall. Many programmers would like parallelization to somehow be done automatically. The fact is that automatic parallelization is already being done at the instruction level, and has been done for decades, but has reached its limits. Hardware is naturally parallel, and modern processors typically include a large amount of circuitry to extract available parallelism from serial instruction streams. LP can only deliver constant factors of speedup and cannot deliver continuously scaling performance over time.

Programming has long been done primarily as if computers were serial machines. Meanwhile, computer architects (and compiler writers) worked diligently to find ways to automatically extract parallelism, via ILP, from their code. For 40 years, it was possible to maintain this illusion of a serial programming model and write reasonably efficient programs while largely ignoring the true parallel nature of hardware. However, the point of decreasing returns has been passed with ILP techniques, and most computer architects believe that these techniques have reached their limit. The ILP wall reflects the fact that the automatically extractable low-level parallelism has already been used up.\\

The memory wall results because off-chip memory rates have not grown as fast as on-chip computation rates. This is due to several factors, including power and the number of pins that can be easily incorporated into an integrated package. Despite recent advances, such as double-data-rate (DDR) signaling, off-chip communication is still relatively slow and power-hungry. Many of the transistors used in today\textquotesingle s processors are for cache, a form of on-chip memory that can help with this problem. However, the performance of many applications is fundamentally bounded by memory performance, not compute performance. Many programmers have been able to ignore this due to the effectiveness of large caches for serial processors. However, for parallel processors, interprocessor communication is also bounded by the memory wall, and this can severely limit scalability. Actually, there are two problems with memory (and communication): latency and bandwidth . Bandwidth (overall data rate) can still be scaled in several ways, such as optical interconnections, but latency (the time between when a request is submitted and when it is satisfied) is subject to fundamental limits, such as the speed of light. Fortunately latency can be hidden?given sufficient additional parallelism, above and beyond that required to satisfy multiple computational units. So the memory wall has two effects: Algorithms need to be structured to avoid memory access and communication as much as possible, and fundamental limits on latency create even more requirements for parallelism.\\

In summary, in order to achieve increasing performance over time for each new processor generation, you cannot depend on rising clock rates, due to the power wall. You also cannot depend on automatic mechanisms to find (more) parallelism in na?ve serial code, due to the ILP wall. To achieve higher performance, you now have to write explicitly parallel programs. And finally, when you write these parallel programs, the memory wall means that you also have to seriously consider communication and memory access costs and may even have to use additional parallelism to hide latency. Instead of using the growing number of transistors predicted by Moore\textquotesingle s Law for ways to maintain the \enquote{serial processor illusion}, architects of modern processor designs now provide multiple mechanisms for explicit parallelism. However, you must use them, and use them well, in order to achieve performance that will continue to scale over time.\\
The resulting trend in hardware is clear: More and more parallelism at a hardware level will become available for any application that is written to utilize it. However, unlike rising clock rates, non-parallelized application performance will not change without active changes in programming. The \enquote{free lunch} of automatically faster serial applications through faster microprocessors has ended. The new \enquote{free lunch} requires scalable parallel programming. The good news is that if you design a program for scalable parallelism, it will continue to scale as processors with more parallelism become available.\\

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/CpuPower.png}
\caption{Graph of processor total power consumption (log scale). The maximum power consumption of processors saw steady growth for nearly two decades before the multicore era. The inability to dissipate heat with air cooling not only brought this growth to a halt but increased interest in reduced power consumption, greater efficiencies, and mobile operation created more options at lower power as well. \cite{mccool}}
\label{CpuPower}
\end{figure}

Figure \ref{CpuPower}  shows a graph of total power consumption over time. After decades of steady increase in power consumption, the so-called power wall was hit about 2004. Above around 130W, air cooling is no longer practical. Arresting power growth required that clock rates stop climbing. From this chart we can see that modern processors now span a large range of power consumption, with the availability of lower power parts driven by the growth of mobile and embedded computing.

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/CpuCores.png}
\caption{The number of cores and hardware threads per processor was one until around 2004, when growth in hardware threads emerged as the trend instead of growth in clock rate. \cite{mccool}}
\label{CpuCores}
\end{figure}

The resulting trend toward explicit parallelism mechanisms is obvious looking at figure \ref{CpuCores}, which plots the sudden rise in the number of hardware threads after 2004. It is common to refer to hardware parallelism as processor cores and to stress multicore. But it is more precise to speak of hardware threads, since some cores can execute more than one thread at a time. Both are shown in the graph.This date aligns with the halt in the growth in clock rate. The power problem was arrested by adding more cores and more threads in each core rather than increasing the clock rate. This ushered in the multicore era, but using multiple hardware threads requires more software changes than prior changes. During this time vector instructions were added as well, and these provide an additional, multiplicative form of explicit parallelism. Vector parallelism can be seen as an extension of data width parallelism, since both are related to the width of hardware registers and the amount of data that can be processed with a single instruction. A measure of the growth of data width parallelism is shown in figure \ref{DataWidth}. While data width parallelism growth predates the halt in the growth of clock rates, the forces driving multicore parallelism growth are also adding motivation to increase data width. While some automatic parallelization (including vectorization ) is possible, it has not been universally successful. Explicit parallel programming is generally needed to fully exploit these two forms of hardware parallelism capabilities.\\

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/DataWidth.png}
\caption{Growth in data processing widths (log scale), measured as the number of bits in registers over time. At first the width of scalar elements grew, but now the number of elements in a register is growing with the addition of vector (SIMD) instructions that can specify the processing of multiple scalar elements at once. \cite{mccool}}
\label{DataWidth}
\end{figure}

Additional hardware parallelism will continue to be motivated by Moore\textquotesingle s Law coupled with power constraints. This will lead to processor designs that are increasingly complex and diverse. Proper abstraction of parallel programming methods is necessary to be able to deal with this diversity and to deal with the fact that Moore\textquotesingle s Law continues unabated, so the maximum number of cores (and the diversity of processors) will continue to increase.\\

\subsection{Parallel Programming Models}

Unfortunately, none of the most popular programming languages in use today was designed for parallel programming. However, since a large amount of code has already been written in existing serial languages, practically speaking it is necessary to find an evolutionary path that extends existing programming practices and tools to support parallelism. Broadly speaking, while enabling dependable results, parallel programming models should have the following properties:\\

\begin{itemize}
\item \textbf{Performance:} Achievable, scalable, predictable, and tunable. It should be possible to predictably achieve good performance and to scale that performance to larger systems.
\item \textbf{Productivity:} Expressive, composable, debuggable, and maintainable. Programming models should be complete and it should be possible to directly and clearly express efficient implementations for a suitable range of algorithms. Observability and predictability should make it possible to debug and maintain programs. 
\item \textbf{Portability:} Functionality and performance, across operating systems and compilers. Parallel programming models should work on a range of targets, now and into the future.
\end{itemize}

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/ParallelModels.png}
\caption{Parallel programming models supported by Intel. A choice of approaches is available, including pre-optimized parallel libraries; standards such as MPI, Coarray Fortran, OpenMP, and OpenCL; dynamic data-parallel virtual machines such as ArBB; domain-specific languages targeting SPMD vector parallelism such as ISPC; coordination languages such as CnC; and Cilk Plus and TBB. \cite{mccool}}
\label{ParallelModels}
\end{figure}

Figure \ref{ParallelModels} shows the parallel programming models supported by Intel.

\subsection{Speedup and Amdahl\textquotesingle s Law}

Two important metrics related to performance and parallelism are \textbf{speedup} and \textbf{efficiency}. Speedup compares the latency for solving the identical computational problem on one hardware unit (\enquote{worker}) versus on $P$ hardware units:

 \begin{equation}\label{Speedup}
speedup = S_P = \frac{T_1}{T_P}
\end{equation}

where $T_1$ is the latency of the program with one worker and $T_P$ is the latency on $P$ workers.\\

\textbf{Efficiency} is speedup divided by the number of workers:

 \begin{equation}\label{Efficiency}
efficiency = \frac{S_P}{P} = \frac{T_1}{P T_P}
\end{equation}

Efficiency measures return on hardware investment. Ideal efficiency is 1 (often reported as $100\%$), which corresponds to a linear speedup, but many factors can reduce efficiency below this ideal.

An algorithm that runs $P$ times faster on $P$ processors is said to exhibit linear speedup . Linear speedup is rare in practice, since there is extra work involved in distributing work to processors and coordinating them. In addition, an optimal serial algorithm may be able to do less work overall than an optimal parallel algorithm for certain problems, so the achievable speedup may be sublinear in $P$ , even on theoretical ideal machines. Linear speedup is usually considered optimal since we can serialize the parallel algorithm, as noted above, and run it on a serial machine with a linear slowdown as a worst-case baseline.\\

Amdahl said that the execution time $T_1$ of a program falls into two categories: 
\begin{itemize}
\item Time spent doing non-parallelizable serialwork 
\item Time spent doing parallelizable work \\
\end{itemize}

Call these $W_{ser}$ and $W_{par}$, respectively. Given $P$ workers available to do the parallelizable work, the times for sequential execution and parallel execution are:

 \begin{equation}\label{SerialExecTime}
T_1 = W_{ser} + W_{par}
\end{equation}

 \begin{equation}\label{ParallelExecTime}
T_P \geq W_{ser} + \frac{W_{par}}{P}
\end{equation}

Substituting these equations into the definition of speedup in equation \ref{Speedup} gives us:

 \begin{equation}\label{AmdahlSpeedup1}
S_P \leq \frac{W_{ser} + W_{par}}{W_{ser} + \frac{W_{par}}{P}}
\end{equation}

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/AmdahlsLaw.png}
\caption{Amdahl?s Law. Speedup is limited by the non-parallelizable serial portion of the work. \cite{mccool}}
\label{AmdahlsLaw}
\end{figure}

Figure \ref{AmdahlsLaw} shows this bound on speedup. Let $f$ be the non-parallelizable serial fraction of the total work. Then the following equalities hold:

 \begin{equation}\label{SerialPart}
W_{ser} = f T_1
\end{equation}

 \begin{equation}\label{ParallelPart}
W_{par} = (1 - f) T_1
\end{equation}

If we substitute these into equation \ref{AmdahlSpeedup1}, we get

 \begin{equation}\label{AmdahlSpeedup2}
S_P \leq \frac{1}{f+\frac{(1-f)}{P}}
\end{equation}

When the number of processors is infinite, the speedup becomes

 \begin{equation}\label{AmdahlSpeedup3}
S_{\infty} \leq \frac{1}{f}
\end{equation}

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/AmdahlsLawGraph.png}
\caption{Amdahl\textquotesingle s Law: speedup. The scalability of parallelization is limited by the non-parallelizable (serial) portion of the workload. The serial fraction is the percentage of code that is not parallelized. \cite{mccool}}
\label{AmdahlsLawGraph}
\end{figure}

Speedup is limited by the fraction of the work that is not parallelizable, even using an infinite number of processors. If $10\%$ of the application cannot be parallelized, then the maximum speedup is $10 ×$. If $1\%$ of the application cannot be parallelized, then the maximum speedup is $100 ×$. In practice, an infinite number of processors is not available. With fewer processors, the speedup may be reduced, which gives an upper bound on the speedup. Amdahl\textquotesingle s Law is graphed in figure \ref{AmdahlsLawGraph}, which shows the bound for various values of $f$ and $P$. For example, observe that even with $f = 0.001$ (that is, only $0.1\%$ of the application is serial) and $P = 2048$, a program\textquotesingle s speedup is limited to $672 ×$.

\subsection{Opportunity}

Parallelization can reduce power consumption. CMOS is the dominant circuit technology for current computer hardware. CMOS power consumption is the sum of dynamic power consumption and static power consumption \cite{mccool}. For a circuit supply voltage $V$ and operating frequency $f$, CMOS dynamic power dissipation is governed by the proportion

 \begin{equation}\label{PowerConsumption}
P_{dynamic} \propto V^2 f
\end{equation}

The frequency dependence is actually more severe than the equation suggests, because the highest frequency at which a CMOS circuit can operate is roughly proportional to the voltage. Thus dynamic power varies as the cube of the maximum frequency. Static power consumption is nominally independent of frequency but is dependent on voltage. The relation is more complex than for dynamic power, but, for sake of argument, assume it varies cubically with voltage. Since the necessary voltage is proportional to the maximum frequency, the static power consumption varies as the cube of the maximum frequency, too. Under this assumption we can use a simple overall model where the total power consumption varies by the cube of the frequency.\\

Suppose that parallelization speeds up an application by $1.5 ×$ on two cores. You can use this speedup either to reduce latency or reduce power. If your latency requirement is already met, then reducing the clock rate of the cores by $1.5 ×$ will save a significant amount of power. Let $P_1$ be the power consumed by one core running the serial version of the application. Then the power consumed by two cores running the parallel version of the application will be given by: 

 \begin{equation}\label{PowerEquation}
 \begin{aligned}
P_2 & = 2 (\frac{1}{1.5})^3 P_1\\
& \approx 0.6 P_1 
\end{aligned}
\end{equation}

where the factor of 2 arises from having two cores. Using two cores running the parallelized version of the application at the lower clock rate has the same latency but uses (in this case) $40\%$ less power. Unfortunately, reality is not so simple. Current chips have so many transistors that frequency and voltage are already scaled down to near the lower limit just to avoid overheating, so there is not much leeway for raising the frequency. For example, Intel Turbo Boost Technology enables cores to be put to sleep so that the power can be devoted to the remaining cores while keeping the chip within its thermal design power limits. Table \ref{tab:table2} shows an example. Still, the table shows that even low parallel efficiencies offer more performance on this chip than serial execution.\\

\begin{table}[h!]
\centering
\caption{Running Fewer Cores Faster. The table shows how the maximum core frequency for an Intel core i5-2500T chip depends on the number of active cores. The last column shows the parallel efficiency over all four cores required to match the speed of using only one active core. \cite{mccool}}
\label{tab:table2}
\begin{tabular}{ |r|r|r| } 
 \hline
\rowcolor{LightCyan}
 Acive Cores & Maximum Frequency (GHz) & Breakeven Efficiency \\ 
 \hline
 4 & 2.4 & 34\% \\ 
 \hline
 3 & 2.8 & 39\% \\ 
 \hline
 2 & 3.2 & 52\%\\
 \hline
1 & 3.3 & 100\%\\
\hline
\end{tabular}PowerConsumption
\end{table}

Another way to save power is to \enquote{race to sleep}. In this strategy, we try to get the computation done as fast as possible (with the lowest latency) so that all the cores can be put in a sleep state that draws very little power. This approach is attractive if a significant fraction of the wakeful power is fixed regardless of how many cores are running. Especially in mobile devices, parallelism can be used to reduce latency. This reduces the time the device, including its display and other components, is powered up. This not only improves the user experience but also reduces the overall power consumption for performing a user\textquotesingle s task: a win-win.

\subsection{Contributions}

As described above, the use of parallel programming can result in the use of energy savings. The aim of this project is to execute compute intensive tasks in both serial and parallel mode. The power consumption in both modes will be measured using a power profiling tool like pTopW. The measurement energy savings obtained by utilizing all the cores in a CPU will be used to identify any trends in run time versus energy savings. 

\section{MOTIVATION AND BACKGROUND}
\subsection{Motivation}

As described in section \ref{sssec:num1}, the total energy consumption by data centers in the U.S. was 91 billion kWh in 2013. This is projected to increase to 140 billion kWh by 2020. This is a lot of energy that is being consumed. The energy consumption can be reduced by parallel programming and this will result in significant dollar amount savings and reduction in pollution levels and green house gases.  

\subsection{Technologies Used}

The Threading Building Blocks (TBB) programming model has been selected for the purpose of this project. TBB supports parallelism based on a tasking model. It provides the following features: 

\begin{itemize}
\item Template library supporting both regular and irregular parallelism 
\item Direct support for a variety of parallel patterns, including map, fork-join, task graphs, reduction, scan, and pipelines 
\item Efficient work-stealing load balancing 
\item A collection of thread-safe data structures 
\item Efficient low-level primitives for atomic operations and memory allocation 
\end{itemize}

TBB is a library, not a language extension, and thus can be used with with any compiler supporting ISO C++. Because of that, TBB uses C++ features to implement its \enquote{syntax}. TBB requires the use of function objects (also known as functors ) to specify blocks of code to run in parallel. These were somewhat tedious to specify in C++98. However, the C++11 addition of lambda expressions greatly simplifies specifying these blocks of code. TBB relies on templates and generic programming. Generic programming means that algorithms are written with the fewest possible assumptions about data structures, which maximizes potential for reuse. The C++ Standard Template Library (STL) is a good example of generic programming in which the interfaces are specified only by requirements on template types and work across a broad range of types that meet those requirements. TBB follows a similar philosophy. Like Cilk Plus, TBB is based on programming in terms of tasks, not threads. This allows it to reduce overhead and to more efficiently manage resources. As with Cilk Plus, TBB implements a common thread pool shared by all tasks and balances load via work-stealing. Use of this model allows for nested parallelism while avoiding the problem of over-subscription. The TBB implementation generally avoids global locks in its implementation. In particular, there is no global task queue and the memory allocator is lock free. This allows for much more scalability. As discussed later, global locks effectively serialize programs that could otherwise run in parallel. Individual components of TBB may also be used with other parallel programming models. It is common to see the TBB parallel memory allocator used with Cilk Plus or OpenMP programs, for example.\\

\section{EXPERIMENTS}
\subsection{Subjects}

The following computational intensive processes were used to evaluate parallel programming energy savings \cite{wilson}.
 
\begin{itemize}
\item \textbf{Random number generation:} Fill a matrix with pseudo-random numbers based on the number of rows, number of columns and a random number generation seed passed in as parameters. 
\item \textbf{Weighted point selection:} This converts a matrix of integers values into a vector of points based on the input matrix, a Boolean mask matrix showing which points are eligible for consideration, and the number of points to select. 
\item \textbf{Outer product:} This converts a vector of coordinates into a matrix filled with the distance between any two points. 
\item \textbf{Matrix-vector product:} Given a matrix $A$, a vector $V$, and an assumed solution $X$ to the equation $AX = V$, this calculates the actual product $AX = V'$ and then finds the magnitude of the error. 
\end{itemize}

\subsection{Experimental Setup}
\label{sssec:num2}

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/MapPattern.png}
\caption{Map pattern. \cite{mccool}}
\label{MapPattern}
\end{figure}

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/MapReducePattern.png}
\caption{Map-Reduce pattern. \cite{mccool}}
\label{MapReducePattern}
\end{figure}

The Map and Map-Reduce patterns were used for parallel computation. These are illustrated in figures \ref{MapPattern} and \ref{MapReducePattern}. The Map pattern is used for executing tasks that have no dependence on each other. For example, if we need to fill a matrix with random numbers, the Map pattern can be used to fill the elements in parallel. The Map-Reduce pattern is essentially a Map pattern followed by a reduction. This can be used in cases where we need to find the maximum among a set of values. The Map process will return each value one by one and the reduction can be made to return the maximum of these values.\\

The following patterns were used for the compute intensive processes listed in section \ref{sssec:num2}:
\begin{itemize}
\item \textbf{Random Number filled Matrix:} Map pattern used for filling.
\item \textbf{Weighted Point Selection:} Map pattern used for filling matrices. Output vector sorted in parallel. Evenly spaced points selected in parallel using Map pattern.
\item \textbf{Outer Product:} Map pattern for Inter point distances, diagonal values and origin to point distances. Map-Reduce pattern for max off diagonal distance.
\item \textbf{Matrix Vector Product:} Map pattern for matrix filling and multiplication.
\end{itemize}



The following tasks were performed:

\begin{itemize}
\item Implement serial and parallel versions of the four computational processes
\item Execute the processes for large computationally intensive operations
\item Install power profiling tool pTopW
\item Record execution times in serial and parallel modes 
\item Estimate energy consumption in serial and parallel modes using profiling tool
\item Find energy saving resulting from parallel computations
\end{itemize}


\subsection{Experimental Results}

\begin{figure}[!t]
\centering
\includegraphics[width=3.5in]{./figures/Results.png}
\caption{Experimental Results.}
\label{Results}
\end{figure}

The experimental results have been summarized in figure \ref{Results}. Each test for the compute intensive processes listed in section  \ref{sssec:num2}, was run five times each in serial and parallel mode. The results were then averaged. The serial results were normalized and so they always show up as 100\%. The parallel results shown are the actual results divided by the serial results and then expressed as a percentage. For example, figure \ref{Results} shows that the parallel matrix operation took around 70\% of the serial time to complete. The parallel weighted point selection took more time than the serial mode as the parallel mode was not effective in reducing the run time. This demonstrates the fact that parallel programming although very much possible, can be a little complicated to implement \cite{nanz}.\\

We can see that parallel computation, in most cases, is faster than the serial one as expected. However, parallel computation results in higher energy consumption. And that too in a shorter amount of time. This was a result that was totally not expected. It seems that when all cores of a multi-core processor are not being used, the energy consumption is reduced by some mechanism. At the time of running the experiment, the reason for the unexpected result was not known.

\subsection{Threats to Validity}

\textbf{Internal Threats:}
The expected correlation between run time and energy consumption is the basis for this project. The rationale is that when only one core of a CPU is being utilized in serial mode, and the other cores are idle, the idle cores will still be using energy. This energy will be wasted as the idle cores are not productive. However, CPU manufacturers may have already planned for the eventuality that there will be times where only one core is used. The reason would be the usage of legacy software that has been programmed to run in parallel mode and also due to the fact that parallel programming is not trivial and may not be widely adopted.\\

\textbf{External Threats:}
Energy saving obtained by parallel programming on a desktop may not mean that the same would be true in the mobile computing platforms. The reason is that even though energy efficiency is important on all platforms, it is more so in the case of mobile platforms. Mobile CPUs, and possibly CPUs targeted at laptops, may already have architecture that is designed to maximize energy efficiency when only one CPU core is being used.

\section{DISCUSSION}
\subsection{Results Analysis}

The results in figure \ref{Results} that show energy consumption increasing despite reduction is execution time, were very much unexpected. While I was looking for related work in the area of energy saving through use of parallel computing, I was finding studies that were in related areas, but not in this specific area that I was interested in. After getting the results, I suspected that my results were probably the result of the energy efficient characteristics of the Intel CPU used in my laptop. So I changed my search focus to energy efficiency and usage of parallel computing in CPUs and microprocessors. I came across the study by Cebri\' an et. al. \cite{cebrian} on the performance and energy impact of parallelization and vectorization techniques in modern microprocessors. This study provided me with the explanation for my results.\\

As per the study \cite{cebrian}, Intel CPUs have these special built in power controls:

\begin{itemize}
\item Dynamic Voltage and Frequency Scaling (DVFS) is used to reduce power consumption. As dynamic power consumption in a CPU is related to the square of the voltage and clock frequency (see equation \ref{PowerConsumption}), the CPU can control the power and consequently the energy consumption by varying the voltage and/or the clock frequency.
\item Clock gating is used to AND a clock signal with a control signal to turn clocking on/off. This technique is used so as not to clock unused cores.
\item Intel\textquotesingle s Turbo Boost Technology uses per core power gating to disable idle cores and DVFS to overclock active cores. The power gating has the effect of shutting down unused cores. With unused cores shut down, the CPU energy consumption is reduced, and this enables the CPU to overclock its active core so that the computation runs faster while keeping the total energy consumption within limits.
\item On Intel processors, vectorization using SIMD (Single Instruction Multiple Data) instructions results in better energy efficiency when compared to thread parallelism. However SIMD instructions are not portable and are specific to a processor.
\end{itemize}

\section{RELATED WORK}

I could not find any related work on energy saving using parallel computing. I did find two studies that were somewhat related to my topic of interest:

\begin{itemize}
\item Woo et. al. suggested \cite{woo} having a mix of low power and full power consumption cores for energy efficiency
\item Ribic et. al. \cite{ribic} developed Hermes for improving energy efficiency of work stealing applications
\end{itemize}

\section{CONCLUSION/SUMMARY}

Overclocking a single core and shutting down unused cores through clock gating and power gating can result in better energy efficiency when only a single core is being used. When all cores are used, even though the execution is sped up when compared to the serial case, energy used is higher. Serial operation on a single core can execute at a higher clock speed due to Intel\textquotesingle s Turbo Boost Technology. In the case of parallel operation, sine all the cores are active, the CPU is forced to lower the clock speed for keeping energy usage within the limits that it can handle. This results in higher energy consumption in parallel mode.

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure}

% Note that the IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command,
% and the \label for the overall figure must come after \caption.
% \hfil is used as a separator to get equal spacing.
% Watch out that the combined width of all the subfigures on a 
% line do not exceed the text width or a line break will occur.
%
%\begin{figure*}[!t]
%\centering
%\subfloat[Case I]{\includegraphics[width=2.5in]{box}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{box}%
%\label{fig_second_case}}
%\caption{Simulation results for the network.}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat[]), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.
% Be aware that for subfig.sty to generate the (a), (b), etc., subfigure
% labels, the optional argument to \subfloat must be present. If a
% subcaption is not desired, just leave its contents blank,
% e.g., \subfloat[].


% An example of a floating table. Note that, for IEEE style tables, the
% \caption command should come BEFORE the table and, given that table
% captions serve much like titles, are usually capitalized except for words
% such as a, an, and, as, at, but, by, for, in, nor, of, on, or, the, to
% and up, which are usually not capitalized unless they are the first or
% last word of the caption. Table text will default to \footnotesize as
% the IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]Uses in rockets, missiles, battery charge estimation
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that the IEEE does not put floats in the very first column
% - or typically anywhere on the first page for that matter. Also,
% in-text middle ("here") positioning is typically not used, but it
% is allowed and encouraged for Computer Society conferences (but
% not Computer Society journals). Most IEEE journals/conferences use
% top floats exclusively. 
% Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the
% \fnbelowfloat command of the stfloats package.







% conference papers do not normally have an appendix


% use section* for acknowledgment






% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://mirror.ctan.org/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the numb\textbf{er of references
% (used to reserve space for the reference number labels box)
\begin{thebibliography}{1}

\bibitem{whitney}
Whitney, J., and P. Delforge. \emph{Data Center Efficiency Assessment - Scaling Up Energy Efficiency Across the Data Center Industry: Evaluating Key Drivers and Barriers.} NRDC and Anthesis, Rep. IP (2014): 14-08.

\bibitem{woo}
Woo, Dong Hyuk, and Hsien-Hsin S. Lee. \emph{Extending Amdahl's law for energy-efficient computing in the many-core era.} Computer 12 (2008): 24-31.

\bibitem{ribic}
 Ribic, Haris, and Yu David Liu. \emph{Energy-efficient work-stealing language runtimes.} ACM SIGARCH Computer Architecture News. Vol. 42. No. 1. ACM, 2014.

\bibitem{mccool}
 McCool, M. J. (2012). \emph{Structured Parallel Programming: Patterns for Efficient Computation.} Amsterdam: Elsevier, Morgan Kaufman.

\bibitem{nanz}
 Nanz, S. S. (2013). \emph{Examining the expert gap in parallel programming.}  Euro-Par 2013 Parallel Processing. , 434-445.

\bibitem{wilson}
 Wilson, G. V. (1995). \emph{Assessing and comparing the usability of parallel programming systems.} Computer Systems Research Institute.

\bibitem{cebrian}
 Cebri\' an, Juan M., Lasse Natvig, and Jan Christian Meyer. \emph{Performance and energy impact of parallelization and vectorization techniques in modern microprocessors.} Computing 96.12 (2014): 1179-1193.
 
\end{thebibliography}

% that's all folks
\end{document}